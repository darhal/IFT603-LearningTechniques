{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'models.LogisticClassifier'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32md:\\COURS\\UdS\\IFT603-LearningTechniques\\Project\\workspace.ipynb Cell 1\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/COURS/UdS/IFT603-LearningTechniques/Project/workspace.ipynb#X34sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtools\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mDataSet\u001b[39;00m \u001b[39mimport\u001b[39;00m DataSet\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/COURS/UdS/IFT603-LearningTechniques/Project/workspace.ipynb#X34sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtools\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mModelTester\u001b[39;00m \u001b[39mimport\u001b[39;00m ModelTester\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/COURS/UdS/IFT603-LearningTechniques/Project/workspace.ipynb#X34sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m Models\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/COURS/UdS/IFT603-LearningTechniques/Project/workspace.ipynb#X34sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtools\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mMetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/COURS/UdS/IFT603-LearningTechniques/Project/workspace.ipynb#X34sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mmatplotlib\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39minline\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32md:\\COURS\\UdS\\IFT603-LearningTechniques\\Project\\models\\Models.py:2\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mRidgeRegression\u001b[39;00m \u001b[39mimport\u001b[39;00m RidgeRegression\n\u001b[1;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mLogisticClassifier\u001b[39;00m \u001b[39mimport\u001b[39;00m LogisticClassifier\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mSinglePerceptron\u001b[39;00m \u001b[39mimport\u001b[39;00m SinglePerceptron\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mSupportVectorMachine\u001b[39;00m \u001b[39mimport\u001b[39;00m SupportVectorMachine\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'models.LogisticClassifier'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tools.DataLoader import DataLoader\n",
    "from tools.DataSet import DataSet\n",
    "from tools.ModelTester import ModelTester\n",
    "from models import Models\n",
    "from tools.Metrics import *\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (14.0, 8.0) # set default size of plots\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(\"data/train.csv\", class_col_name=\"species\", excluded_features={\"id\"})\n",
    "dl.load()\n",
    "dataset = dl.get_dataset()\n",
    "\n",
    "print(f\"Number of data entries : {len(dataset)}\")\n",
    "print(f\"Number of classes : {len(dataset.group_by_class())}\")\n",
    "\n",
    "grouppedClasses = pd.DataFrame(\n",
    "    data=np.array([ len(ds) for ds in dataset.group_by_class() ]),\n",
    "    columns=[\"Count\"],\n",
    "    index=[f\"{dl.get_label_name(ds.labels[0])}\" for ds in dataset.group_by_class()]\n",
    ")\n",
    "display(grouppedClasses)\n",
    "\n",
    "dataset.shuffle()\n",
    "train_set, test_set = dataset.stratified_split([0.7])\n",
    "print(f\"Train set : {len(train_set)} - Number of classes : {len(train_set.group_by_class())}\")\n",
    "print(f\"Train set : {len(test_set)} - Number of classes : {len(test_set.group_by_class())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Project into the PCA space (2 major axis)\n",
    "pca = PCA()\n",
    "pcaSpace = pca.fit_transform(train_set.features)\n",
    "pcaSpaceXY = (pcaSpace[:,0], pcaSpace[:,1])\n",
    "\n",
    "# Plot PCA axis contributions\n",
    "plt.figure(figsize=(8, 6), dpi=120)\n",
    "plt.plot(pca.explained_variance_ratio_)\n",
    "plt.ylabel(\"Variance\")\n",
    "plt.xlabel(\"Components\")\n",
    "plt.show()\n",
    "\n",
    "# Plot data in the PCA space (2 major axis)\n",
    "plt.figure(figsize=(8, 6), dpi=120)\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "scatter = plt.scatter(x=pcaSpaceXY[0], y=pcaSpaceXY[1], c=train_set.labels, s=15)\n",
    "plt.legend(handles=scatter.legend_elements(num=3)[0], labels=dl.classes)\n",
    "plt.title(\"Data represented in the PCA space\", loc='center', wrap=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression :\n",
    "mt = ModelTester(\"LogisticClassifier\")\n",
    "mt.test(dataset, train_set, test_set)\n",
    "\n",
    "# Ridge Regression : \n",
    "mt = ModelTester(\"RidgeRegression\")\n",
    "mt.test(dataset, train_set, test_set)\n",
    "\n",
    "# Perceptron : \n",
    "mt = ModelTester(\"SinglePerceptron\")\n",
    "mt.test(dataset, train_set, test_set)\n",
    "\n",
    "# SVM : \n",
    "mt = ModelTester(\"SupportVectorMachine\")\n",
    "mt.test(dataset, train_set, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "mt = ModelTester(\"RandomForest\")\n",
    "mt.test(dataset, train_set, test_set)\n",
    "\n",
    "# Ada Boost\n",
    "mt = ModelTester(\"AdaBoost\")\n",
    "mt.test(dataset, train_set, test_set)\n",
    "\n",
    "# Gradient Boosted Trees\n",
    "# mt = ModelTester(\"GradientBoostedTrees\")\n",
    "# mt.test(dataset, train_set, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt = ModelTester(\"MultiLayerPerceptron\")\n",
    "mt.test(dataset, train_set, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.Models import *\n",
    "\n",
    "# Load Test Data\n",
    "test_dl = DataLoader(\"data/test.csv\", class_col_name=\"id\")\n",
    "test_dl.load()\n",
    "submission_set = test_dl.get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best out of all\n",
    "lc = LogisticClassifier(stand_trans=True)\n",
    "lc.train(dataset)\n",
    "probs, classes = lc.predict_probs(submission_set.features)\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    data=probs,\n",
    "    columns=dl.classes,\n",
    "    index=test_dl.classes\n",
    ")\n",
    "display(df)\n",
    "df.to_csv(\"submissions/logi_submission.csv\", index_label=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd best\n",
    "mlp = MultiLayerPerceptron(stand_trans=True)\n",
    "mlp.train(dataset)\n",
    "probs, classes = mlp.predict_probs(submission_set.features)\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    data=probs,\n",
    "    columns=dl.classes,\n",
    "    index=test_dl.classes\n",
    ")\n",
    "display(df)\n",
    "df.to_csv(\"submissions/mlp_submission.csv\", index_label=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3rd best\n",
    "svm = SupportVectorMachine(stand_trans=True)\n",
    "svm.train(dataset)\n",
    "probs, classes = svm.predict_probs(submission_set.features)\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    data=probs,\n",
    "    columns=dl.classes,\n",
    "    index=test_dl.classes\n",
    ")\n",
    "display(df)\n",
    "df.to_csv(\"submissions/svm_submission.csv\", index_label=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForest(stand_trans=True)\n",
    "rf.train(dataset)\n",
    "probs, classes = rf.predict_probs(submission_set.features)\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    data=probs,\n",
    "    columns=dl.classes,\n",
    "    index=test_dl.classes\n",
    ")\n",
    "display(df)\n",
    "df.to_csv(\"submissions/rf_submission.csv\", index_label=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr = RidgeRegression(stand_trans=True)\n",
    "rr.train(dataset)\n",
    "probs, classes = rr.predict_probs(submission_set.features)\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    data=probs,\n",
    "    columns=dl.classes,\n",
    "    index=test_dl.classes\n",
    ")\n",
    "display(df)\n",
    "df.to_csv(\"submissions/rr_submission.csv\", index_label=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = SinglePerceptron(stand_trans=True)\n",
    "sp.train(dataset)\n",
    "probs, classes = sp.predict_probs(submission_set.features)\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    data=probs,\n",
    "    columns=dl.classes,\n",
    "    index=test_dl.classes\n",
    ")\n",
    "display(df)\n",
    "df.to_csv(\"submissions/sp_submission.csv\", index_label=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab = AdaBoost(stand_trans=True)\n",
    "ab.train(dataset)\n",
    "probs, classes = ab.predict_probs(submission_set.features)\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    data=probs,\n",
    "    columns=dl.classes,\n",
    "    index=test_dl.classes\n",
    ")\n",
    "display(df)\n",
    "df.to_csv(\"submissions/ab_submission.csv\", index_label=\"id\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "501834c540f8b330c04c1d43ec1666643355d13f80c9caf7e1080236b3fb263f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
